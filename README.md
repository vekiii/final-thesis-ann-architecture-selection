# Final Thesis
## An Empirical Approach to Optimal Three-Layer Artificial Neural Network Architecture Selection for Data Classification

## ðŸ“˜ Abstract
This final thesis presents an empirical analysis of the performance of a three-layer artificial neural network (ANN) in solving binary and multi-class data classification problems. The main objective of the thesis was to use MATLAB tools to define a methodology for selecting the optimal network architecture and to quantitatively measure the impact of key parameters on the classification result.

## ðŸ”¬ Methodology
The following aspects were investigated:
- Number of neurons in the hidden layer and its impact on overfitting and underfitting
- Optimization algorithms: Scaled Conjugate Gradient (SCG) vs. Levenbergâ€“Marquardt (LM)
- Dataset quality through three case studies with varying levels of non-linearity and correlation

## ðŸ“Š Key Contributions and Conclusions
- **Levenbergâ€“Marquardt dominance:** Empirically shown to outperform SCG, reducing test error and increasing model confidence on complex datasets
- **Overfitting rule:** Increasing hidden-layer neurons beyond the optimal value (â‰ˆ10 in most simulations) leads to performance degradation on the test set
- **Irreducible error identification:** Demonstrated in low-correlation datasets, showing model performance limited by data quality

## ðŸ›  Tools
- MATLAB
- Artificial Neural Networks (ANN)
- Supervised classification

- ---

## Â© Copyright

Â© 2025 Vedran MitiÄ‡. All rights reserved.

This thesis and accompanying materials may not be reproduced or distributed without the author's permission.

